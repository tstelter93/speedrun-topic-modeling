{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First submission element \n",
      "\n",
      "{'archived': True,\n",
      " 'author': 'intheblue',\n",
      " 'author_flair_css_class': '',\n",
      " 'author_flair_text': 'Hotline Miami, Spider Solitare',\n",
      " 'created': 1417395407,\n",
      " 'created_utc': '1417395407',\n",
      " 'distinguished': None,\n",
      " 'domain': 'twitch.tv',\n",
      " 'downs': 0,\n",
      " 'edited': False,\n",
      " 'from': None,\n",
      " 'from_id': None,\n",
      " 'from_kind': None,\n",
      " 'gilded': 0,\n",
      " 'hide_score': False,\n",
      " 'id': '2nw69z',\n",
      " 'is_self': False,\n",
      " 'link_flair_css_class': None,\n",
      " 'link_flair_text': None,\n",
      " 'media': {'oembed': {'description': 'Recorded live on an hour ago',\n",
      "                      'height': 300,\n",
      "                      'html': '&lt;iframe class=\"embedly-embed\" '\n",
      "                              'src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.twitch.tv%2Fwidgets%2Flive_embed_player.swf%3Fchannel%3Ddingodroles&amp;fv=hostname%3Dwww.twitch.tv%26start_volume%3D25%26channel%3Ddingodrole%26auto_play%3Dfalse&amp;url=http%3A%2F%2Fwww.twitch.tv%2Fdingodrole%2Fc%2F5593916&amp;image=http%3A%2F%2Fstatic-cdn.jtvnw.net%2Fjtv_user_pictures%2Fpanel-31452198-image-6e137cc829bea5a9-320.jpeg&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=application%2Fx-shockwave-flash&amp;schema=twitch\" '\n",
      "                              'width=\"400\" height=\"300\" scrolling=\"no\" '\n",
      "                              'frameborder=\"0\" '\n",
      "                              'allowfullscreen&gt;&lt;/iframe&gt;',\n",
      "                      'provider_name': 'Twitch.tv',\n",
      "                      'provider_url': 'http://www.twitch.tv',\n",
      "                      'thumbnail_height': 240,\n",
      "                      'thumbnail_url': 'http://static-cdn.jtvnw.net/jtv.thumbs/archive-594375235-320x240.jpg',\n",
      "                      'thumbnail_width': 320,\n",
      "                      'title': 'Hotline Miami any% NG ( 20:16 )',\n",
      "                      'type': 'video',\n",
      "                      'version': '1.0',\n",
      "                      'width': 400},\n",
      "           'type': 'twitch.tv'},\n",
      " 'media_embed': {'content': '&lt;iframe class=\"embedly-embed\" '\n",
      "                            'src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.twitch.tv%2Fwidgets%2Flive_embed_player.swf%3Fchannel%3Ddingodroles&amp;fv=hostname%3Dwww.twitch.tv%26start_volume%3D25%26channel%3Ddingodrole%26auto_play%3Dfalse&amp;url=http%3A%2F%2Fwww.twitch.tv%2Fdingodrole%2Fc%2F5593916&amp;image=http%3A%2F%2Fstatic-cdn.jtvnw.net%2Fjtv_user_pictures%2Fpanel-31452198-image-6e137cc829bea5a9-320.jpeg&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=application%2Fx-shockwave-flash&amp;schema=twitch\" '\n",
      "                            'width=\"400\" height=\"300\" scrolling=\"no\" '\n",
      "                            'frameborder=\"0\" '\n",
      "                            'allowfullscreen&gt;&lt;/iframe&gt;',\n",
      "                 'height': 300,\n",
      "                 'scrolling': False,\n",
      "                 'width': 400},\n",
      " 'name': 't3_2nw69z',\n",
      " 'num_comments': 6,\n",
      " 'over_18': False,\n",
      " 'permalink': '/r/speedrun/comments/2nw69z/wrhotline_miami_any_ng_in_2016_by_dingodrole/',\n",
      " 'quarantine': False,\n",
      " 'retrieved_on': 1441043841,\n",
      " 'saved': False,\n",
      " 'score': 37,\n",
      " 'secure_media': None,\n",
      " 'secure_media_embed': {},\n",
      " 'selftext': '',\n",
      " 'stickied': False,\n",
      " 'subreddit': 'speedrun',\n",
      " 'subreddit_id': 't5_2sf9e',\n",
      " 'thumbnail': 'http://b.thumbs.redditmedia.com/8eH-7LJF0WhS59rAEiPwqtxlVpWGdTJ_dmliPHSZQXU.jpg',\n",
      " 'title': '[WR]Hotline Miami Any% NG in 20:16 by Dingodrole',\n",
      " 'ups': 37,\n",
      " 'url': 'http://www.twitch.tv/dingodrole/c/5593916'}\n",
      "\n",
      "\n",
      "First Comment element \n",
      "\n",
      "{'archived': False,\n",
      " 'author': 'I_am_NOT_Steve',\n",
      " 'author_flair_css_class': '',\n",
      " 'author_flair_text': 'Shenanagans_',\n",
      " 'body': 'this only beats my PB time by around a minute :/ a TAS of this '\n",
      "         'should be pretty close to 48:30 easily...',\n",
      " 'controversiality': 0,\n",
      " 'created_utc': '1417392166',\n",
      " 'distinguished': None,\n",
      " 'downs': 0,\n",
      " 'edited': False,\n",
      " 'gilded': 0,\n",
      " 'id': 'cmhepwg',\n",
      " 'link_id': 't3_2nvw48',\n",
      " 'name': 't1_cmhepwg',\n",
      " 'parent_id': 't3_2nvw48',\n",
      " 'retrieved_on': 1425748636,\n",
      " 'score': 6,\n",
      " 'score_hidden': False,\n",
      " 'subreddit': 'speedrun',\n",
      " 'subreddit_id': 't5_2sf9e',\n",
      " 'ups': 6}\n"
     ]
    }
   ],
   "source": [
    "# Import the Data\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#Read in submissions\n",
    "with open('r_data/RS_2014-12_speedrun.json', 'r', encoding='utf-8') as file:\n",
    "    submission_dataset = json.loads(file.read())\n",
    "\n",
    "# Read in comments\n",
    "with open('r_data/RC_2014-12_speedrun.json', 'r', encoding='utf-8') as file:\n",
    "    comment_dataset = json.loads(file.read())\n",
    "\n",
    "file.close()\n",
    "#pprint(type(submission_dataset))\n",
    "print(\"First submission element \\n\")\n",
    "pprint(submission_dataset[0])\n",
    "print(\"\\n\")\n",
    "print(\"First Comment element \\n\")\n",
    "pprint(comment_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission 0:  \n",
      "{'id': '2nw69z', 'title': '[WR]Hotline Miami Any% NG in 20:16 by Dingodrole', 'selftext': '', 'score': 37, 'num_comments': 6}\n",
      "\n",
      "\n",
      "Comment 0:  \n",
      "{'parent_id': 't3_2nvw48', 'body': 'this only beats my PB time by around a minute :/ a TAS of this should be pretty close to 48:30 easily...', 'score': 6}\n"
     ]
    }
   ],
   "source": [
    "# Data preporcessing part 1\n",
    "# We curate the tags we want.       \n",
    "\n",
    "# process submission\n",
    "info = {}\n",
    "submission_dataset_two = []\n",
    "for dictionary in submission_dataset:\n",
    "    info = {\n",
    "        \"id\":            dictionary.get('id'),\n",
    "        \"title\":         dictionary.get('title'),\n",
    "        \"selftext\":      dictionary.get('selftext'),\n",
    "        \"score\":         dictionary.get('score'),\n",
    "        \"num_comments\":  dictionary.get('num_comments')\n",
    "    }\n",
    "    submission_dataset_two.append(info)\n",
    "print(\"Submission 0:  \")\n",
    "print(submission_dataset_two[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "info_two = {}\n",
    "comment_dataset_two = []\n",
    "for dictionary in comment_dataset:\n",
    "    info_two = {\n",
    "        \"parent_id\": dictionary.get('parent_id'),\n",
    "        \"body\":      dictionary.get('body'),\n",
    "        \"score\":     dictionary.get('score')\n",
    "    }\n",
    "    comment_dataset_two.append(info_two)\n",
    "print(\"Comment 0:  \")\n",
    "print(comment_dataset_two[0])\n",
    "\n",
    "with open('r_data/sub_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(submission_dataset_two, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('r_data/com_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(comment_dataset_two, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic model LDA\n",
    "# First attempt is to use Sub title + self text to generate topics\n",
    "# Second attempt is to use just sub title + comments\n",
    "# third attempt is just look at comments\n",
    "# fourth is title + self text + comments\n",
    "#Read in curated submissions\n",
    "# Code by ... from: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/ for Gensim model NOT USED\n",
    "# Code by ... from: https://stackabuse.com/python-for-nlp-topic-modeling/ for LDA model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# shows the data\n",
    "# submission_dataset_three.dropna()\n",
    "\n",
    "######This is for Title only#####\n",
    "\n",
    "# submission_dataset_three = pd.read_json(r'r_data/sub_data.json')\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "# doc_term_matrix = count_vect.fit_transform(submission_dataset_three['title'].values.astype('U'))\n",
    "\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "# LDA.fit(doc_term_matrix)\n",
    "\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "\n",
    "with open('r_data/sub_data.json', 'r', encoding='utf-8') as file:\n",
    "    submission_dataset_three = json.loads(file.read())\n",
    "\n",
    "file.close()\n",
    "corpus = {}\n",
    "corpus_two = []\n",
    "\n",
    "for dictionary in submission_dataset_three:\n",
    "    corpus = {\n",
    "        \"data\": dictionary.get('title') + dictionary.get('selftext')\n",
    "        \"id\":            dictionary.get('id'),\n",
    "        \"score\":         dictionary.get('score'),\n",
    "        \"num_comments\":  dictionary.get('num_comments')\n",
    "    }\n",
    "    corpus_two.append(corpus)\n",
    "\n",
    "with open('r_data/sub_title_selftext_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(corpus_two, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "title_selftext = pd.read_json(r'r_data/sub_title_selftext_data.json')\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(title_selftext['data'].values.astype('U'))\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# pprint(doc_term_matrix.toarray())\n",
    "\n",
    "# for i in range(10):\n",
    "#     random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "#     print(count_vect.get_feature_names()[random_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['speedrun', 'box', 'com', 've', 'run', 'just', 'speedrunning', 'http', 'runs', 'game']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['guys', 'time', 'agdq', 'know', 'speed', 'speedrunning', 'just', 'games', 'game', 'run']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['12', 'time', 'tv', 'new', 'race', 'www', 'twitch', 'mario', 'http', 'super']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['10', 'help', 'speedrunning', 'www', 'like', 'http', 'game', 'cards', 'speedrun', 'marathon']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['race', 'watch', 'time', 'https', 'twitch', 'run', 'com', 'youtube', 'www', 'wr']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print words -- manually look at topics\n",
    "first_topic = LDA.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "\n",
    "# for i in top_topic_words:\n",
    "#     print(count_vect.get_feature_names()[i])\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of all topics to each document\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[WR]Hotline Miami Any% NG in 20:16 by Dingodrole</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Couple questions about Chrono Trigger Any%1) W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[WR] Luigi's Mansion 100% new WR by Veman300! ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Jak and Daxter any% route?Does anyone know of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[WR] Castlevania:Harmony Of Dissonance Maxim A...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>What do you consider some of the most impressi...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Rayman PSX (emulator) in 1:24:05</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Anybody speedrun games for iOS/Android? Let's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SSX On Tour - The Peak Freeride in 14:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Dark Souls 2 latest exe?Can someone post the l...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  Topic\n",
       "0   [WR]Hotline Miami Any% NG in 20:16 by Dingodrole      4\n",
       "1  Couple questions about Chrono Trigger Any%1) W...      1\n",
       "2  [WR] Luigi's Mansion 100% new WR by Veman300! ...      3\n",
       "3  Jak and Daxter any% route?Does anyone know of ...      1\n",
       "4  [WR] Castlevania:Harmony Of Dissonance Maxim A...      4\n",
       "5  What do you consider some of the most impressi...      3\n",
       "6                   Rayman PSX (emulator) in 1:24:05      3\n",
       "7  Anybody speedrun games for iOS/Android? Let's ...      1\n",
       "8           SSX On Tour - The Peak Freeride in 14:00      0\n",
       "9  Dark Souls 2 latest exe?Can someone post the l...      3"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the topic index with max value\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "# submission_dataset_three['Topic'] = topic_values.argmax(axis=1)\n",
    "# submission_dataset_three.head(10)\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "title_selftext['Topic'] = topic_values.argmax(axis=1)\n",
    "title_selftext.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
