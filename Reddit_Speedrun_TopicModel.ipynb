{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First submission element \n",
      "\n",
      "{'archived': True,\n",
      " 'author': 'intheblue',\n",
      " 'author_flair_css_class': '',\n",
      " 'author_flair_text': 'Hotline Miami, Spider Solitare',\n",
      " 'created': 1417395407,\n",
      " 'created_utc': '1417395407',\n",
      " 'distinguished': None,\n",
      " 'domain': 'twitch.tv',\n",
      " 'downs': 0,\n",
      " 'edited': False,\n",
      " 'from': None,\n",
      " 'from_id': None,\n",
      " 'from_kind': None,\n",
      " 'gilded': 0,\n",
      " 'hide_score': False,\n",
      " 'id': '2nw69z',\n",
      " 'is_self': False,\n",
      " 'link_flair_css_class': None,\n",
      " 'link_flair_text': None,\n",
      " 'media': {'oembed': {'description': 'Recorded live on an hour ago',\n",
      "                      'height': 300,\n",
      "                      'html': '&lt;iframe class=\"embedly-embed\" '\n",
      "                              'src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.twitch.tv%2Fwidgets%2Flive_embed_player.swf%3Fchannel%3Ddingodroles&amp;fv=hostname%3Dwww.twitch.tv%26start_volume%3D25%26channel%3Ddingodrole%26auto_play%3Dfalse&amp;url=http%3A%2F%2Fwww.twitch.tv%2Fdingodrole%2Fc%2F5593916&amp;image=http%3A%2F%2Fstatic-cdn.jtvnw.net%2Fjtv_user_pictures%2Fpanel-31452198-image-6e137cc829bea5a9-320.jpeg&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=application%2Fx-shockwave-flash&amp;schema=twitch\" '\n",
      "                              'width=\"400\" height=\"300\" scrolling=\"no\" '\n",
      "                              'frameborder=\"0\" '\n",
      "                              'allowfullscreen&gt;&lt;/iframe&gt;',\n",
      "                      'provider_name': 'Twitch.tv',\n",
      "                      'provider_url': 'http://www.twitch.tv',\n",
      "                      'thumbnail_height': 240,\n",
      "                      'thumbnail_url': 'http://static-cdn.jtvnw.net/jtv.thumbs/archive-594375235-320x240.jpg',\n",
      "                      'thumbnail_width': 320,\n",
      "                      'title': 'Hotline Miami any% NG ( 20:16 )',\n",
      "                      'type': 'video',\n",
      "                      'version': '1.0',\n",
      "                      'width': 400},\n",
      "           'type': 'twitch.tv'},\n",
      " 'media_embed': {'content': '&lt;iframe class=\"embedly-embed\" '\n",
      "                            'src=\"//cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.twitch.tv%2Fwidgets%2Flive_embed_player.swf%3Fchannel%3Ddingodroles&amp;fv=hostname%3Dwww.twitch.tv%26start_volume%3D25%26channel%3Ddingodrole%26auto_play%3Dfalse&amp;url=http%3A%2F%2Fwww.twitch.tv%2Fdingodrole%2Fc%2F5593916&amp;image=http%3A%2F%2Fstatic-cdn.jtvnw.net%2Fjtv_user_pictures%2Fpanel-31452198-image-6e137cc829bea5a9-320.jpeg&amp;key=2aa3c4d5f3de4f5b9120b660ad850dc9&amp;type=application%2Fx-shockwave-flash&amp;schema=twitch\" '\n",
      "                            'width=\"400\" height=\"300\" scrolling=\"no\" '\n",
      "                            'frameborder=\"0\" '\n",
      "                            'allowfullscreen&gt;&lt;/iframe&gt;',\n",
      "                 'height': 300,\n",
      "                 'scrolling': False,\n",
      "                 'width': 400},\n",
      " 'name': 't3_2nw69z',\n",
      " 'num_comments': 6,\n",
      " 'over_18': False,\n",
      " 'permalink': '/r/speedrun/comments/2nw69z/wrhotline_miami_any_ng_in_2016_by_dingodrole/',\n",
      " 'quarantine': False,\n",
      " 'retrieved_on': 1441043841,\n",
      " 'saved': False,\n",
      " 'score': 37,\n",
      " 'secure_media': None,\n",
      " 'secure_media_embed': {},\n",
      " 'selftext': '',\n",
      " 'stickied': False,\n",
      " 'subreddit': 'speedrun',\n",
      " 'subreddit_id': 't5_2sf9e',\n",
      " 'thumbnail': 'http://b.thumbs.redditmedia.com/8eH-7LJF0WhS59rAEiPwqtxlVpWGdTJ_dmliPHSZQXU.jpg',\n",
      " 'title': '[WR]Hotline Miami Any% NG in 20:16 by Dingodrole',\n",
      " 'ups': 37,\n",
      " 'url': 'http://www.twitch.tv/dingodrole/c/5593916'}\n",
      "\n",
      "\n",
      "First Comment element \n",
      "\n",
      "{'archived': False,\n",
      " 'author': 'I_am_NOT_Steve',\n",
      " 'author_flair_css_class': '',\n",
      " 'author_flair_text': 'Shenanagans_',\n",
      " 'body': 'this only beats my PB time by around a minute :/ a TAS of this '\n",
      "         'should be pretty close to 48:30 easily...',\n",
      " 'controversiality': 0,\n",
      " 'created_utc': '1417392166',\n",
      " 'distinguished': None,\n",
      " 'downs': 0,\n",
      " 'edited': False,\n",
      " 'gilded': 0,\n",
      " 'id': 'cmhepwg',\n",
      " 'link_id': 't3_2nvw48',\n",
      " 'name': 't1_cmhepwg',\n",
      " 'parent_id': 't3_2nvw48',\n",
      " 'retrieved_on': 1425748636,\n",
      " 'score': 6,\n",
      " 'score_hidden': False,\n",
      " 'subreddit': 'speedrun',\n",
      " 'subreddit_id': 't5_2sf9e',\n",
      " 'ups': 6}\n"
     ]
    }
   ],
   "source": [
    "# Import the Data\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "#Read in submissions\n",
    "with open('r_data/RS_2014-12_speedrun.json', 'r', encoding='utf-8') as file:\n",
    "    submission_dataset = json.loads(file.read())\n",
    "\n",
    "# Read in comments\n",
    "with open('r_data/RC_2014-12_speedrun.json', 'r', encoding='utf-8') as file:\n",
    "    comment_dataset = json.loads(file.read())\n",
    "\n",
    "file.close()\n",
    "#pprint(type(submission_dataset))\n",
    "print(\"First submission element \\n\")\n",
    "pprint(submission_dataset[0])\n",
    "print(\"\\n\")\n",
    "print(\"First Comment element \\n\")\n",
    "pprint(comment_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission 0:  \n",
      "{'id': '2nw69z', 'name': 't3_2nw69z', 'title': '[WR]Hotline Miami Any% NG in 20:16 by Dingodrole', 'selftext': '', 'score': 37, 'num_comments': 6}\n",
      "\n",
      "\n",
      "Comment 0:  \n",
      "{'parent_id': 't3_2nvw48', 'body': 'this only beats my PB time by around a minute :/ a TAS of this should be pretty close to 48:30 easily...', 'score': 6}\n"
     ]
    }
   ],
   "source": [
    "# Data preporcessing part 1\n",
    "# We curate the tags we want.       \n",
    "\n",
    "# process submission\n",
    "info = {}\n",
    "submission_dataset_two = []\n",
    "for dictionary in submission_dataset:\n",
    "    info = {\n",
    "        \"id\":            dictionary.get('id'),\n",
    "        \"name\":            dictionary.get('name'),\n",
    "        \"title\":         dictionary.get('title'),\n",
    "        \"selftext\":      dictionary.get('selftext'),\n",
    "        \"score\":         dictionary.get('score'),\n",
    "        \"num_comments\":  dictionary.get('num_comments')\n",
    "    }\n",
    "    submission_dataset_two.append(info)\n",
    "print(\"Submission 0:  \")\n",
    "print(submission_dataset_two[0])\n",
    "print(\"\\n\")\n",
    "\n",
    "info_two = {}\n",
    "comment_dataset_two = []\n",
    "for dictionary in comment_dataset:\n",
    "    info_two = {\n",
    "        \"parent_id\":        dictionary.get('parent_id'),\n",
    "        \"body\":      dictionary.get('body'),\n",
    "        \"score\":     dictionary.get('score')\n",
    "    }\n",
    "    comment_dataset_two.append(info_two)\n",
    "print(\"Comment 0:  \")\n",
    "print(comment_dataset_two[0])\n",
    "\n",
    "with open('r_data/sub_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(submission_dataset_two, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('r_data/com_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(comment_dataset_two, file, ensure_ascii=False, indent=4)\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': 'Couple questions about Chrono Trigger Any%1) Where can I find more '\n",
      "         'information on the rng manipulation of this game? All I really know '\n",
      "         'is that I need to pick my save file really fast.  \\n'\n",
      "         '2) The route I have suggests to hold x during battles, which is '\n",
      "         'apparently supposed to automatically select attack for you, but I '\n",
      "         'have experienced no such functionality. Is there a setting I have '\n",
      "         'forgotten in-game?1) http://chrono.wikidot.com/strategies . The '\n",
      "         'route has all the loads you need, so basically if you load on the '\n",
      "         'desired time frame and get into no extra battles you are good, if '\n",
      "         'you get into extra battles the rng gets mixed up and there are '\n",
      "         'safety saves with their respective loads in the route for the '\n",
      "         'crucial parts\\n'\n",
      "         '\\n'\n",
      "         '2) http://chrono.wikidot.com/strategies At the start of the route it '\n",
      "         'says to Battle Speed 1 + battle cursor set to memory, the battle '\n",
      "         \"cursor on memory makes that function available. It's really \"\n",
      "         'important (be prepared to attack with X always, never use A on '\n",
      "         'attack).\\n'\n",
      "         '\\n'\n",
      "         \"I'd suggest watching the WR run: bombch.us/tYN It's a good run with \"\n",
      "         'no manipulation mistakes to aid you in your learning (that being '\n",
      "         'said run is very improvable).\\n'\n",
      "         '\\n'\n",
      "         'Any other questions feel free to pm me on twitch or check #chrono on '\n",
      "         'SRL irc. There are always persons there who can help. Happy learning '\n",
      "         ':D\\n'\n",
      "         '\\n'\n",
      "         'Cheers'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=5, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Topic model LDA\n",
    "# First attempt is to use Sub title + self text to generate topics\n",
    "# Second attempt is to use just sub title + comments\n",
    "# third attempt is just look at comments\n",
    "# fourth is title + self text + comments\n",
    "#Read in curated submissions\n",
    "# Code by ... from: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/ for Gensim model NOT USED\n",
    "# Code by ... from: https://stackabuse.com/python-for-nlp-topic-modeling/ for LDA model\n",
    "#Additional resources\n",
    "##https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation\n",
    "##https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# shows the data\n",
    "# submission_dataset_three.dropna()\n",
    "\n",
    "######This is for Title only#####\n",
    "\n",
    "# submission_dataset_three = pd.read_json(r'r_data/sub_data.json')\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "# doc_term_matrix = count_vect.fit_transform(submission_dataset_three['title'].values.astype('U'))\n",
    "\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "# LDA.fit(doc_term_matrix)\n",
    "\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "\n",
    "# with open('r_data/sub_data.json', 'r', encoding='utf-8') as file:\n",
    "#     submission_dataset_three = json.loads(file.read())\n",
    "\n",
    "# file.close()\n",
    "# corpus = {}\n",
    "# corpus_two = []\n",
    "\n",
    "# for dictionary in submission_dataset_three:\n",
    "    \n",
    "#     #do some cleaning here of spaces, lower textcasing etc.\n",
    "    \n",
    "#     corpus = {\n",
    "#         \"data\": dictionary.get('title') + dictionary.get('selftext')\n",
    "#     }\n",
    "#     corpus_two.append(corpus)\n",
    "\n",
    "# pprint(corpus_two[1])\n",
    "    \n",
    "# with open('r_data/sub_title_selftext_data.json', 'w', encoding='utf-8') as file:\n",
    "#     json.dump(corpus_two, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# title_selftext = pd.read_json(r'r_data/sub_title_selftext_data.json')\n",
    "    \n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "# doc_term_matrix = count_vect.fit_transform(title_selftext['data'].values.astype('U'))\n",
    "\n",
    "# from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "# LDA.fit(doc_term_matrix)\n",
    "\n",
    "\n",
    "#####This is for title + selftext + comments#####\n",
    "\n",
    "with open('r_data/sub_data.json', 'r', encoding='utf-8') as file:\n",
    "    submission_dataset_three = json.loads(file.read())\n",
    "\n",
    "with open('r_data/com_data.json', 'r', encoding='utf-8') as file:\n",
    "    comment_dataset_three = json.loads(file.read())\n",
    "    \n",
    "file.close()\n",
    "corpus = {}\n",
    "corpus_two = []\n",
    "\n",
    "for dictionary in submission_dataset_three:\n",
    "    \n",
    "    sub_id = dictionary.get('name')\n",
    "    comment_list = \"\"\n",
    "    \n",
    "    for comment in comment_dataset_three:\n",
    "        if sub_id == comment.get('parent_id'):\n",
    "#             print(sub_id)\n",
    "#             print(comment.get('parent_id'))\n",
    "#             print(comment.get('body'))\n",
    "            comment_list = comment_list + comment.get('body')\n",
    "    \n",
    "    #do some cleaning here of spaces, lower textcasing etc.\n",
    "    \n",
    "    corpus = {\n",
    "        \"data\": dictionary.get('title') + dictionary.get('selftext') + comment_list\n",
    "    }\n",
    "    corpus_two.append(corpus)\n",
    "\n",
    "\n",
    "pprint(corpus_two[1])\n",
    "    \n",
    "with open('r_data/sub_title_selftext_comment_data.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(corpus_two, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "title_selftext_comment = pd.read_json(r'r_data/sub_title_selftext_comment_data.json')\n",
    "    \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')\n",
    "doc_term_matrix = count_vect.fit_transform(title_selftext_comment['data'].values.astype('U'))\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDA = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "LDA.fit(doc_term_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# pprint(doc_term_matrix.toarray())\n",
    "\n",
    "# for i in range(10):\n",
    "#     random_id = random.randint(0,len(count_vect.get_feature_names()))\n",
    "#     print(count_vect.get_feature_names()[random_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for topic #0:\n",
      "['watch', 'game', 'youtube', 'thefastforce', 'com', 'wr', 'www', 'tv', 'twitch', 'http']\n",
      "\n",
      "\n",
      "Top 10 words for topic #1:\n",
      "['speedrun', 'good', 'don', 'mario', 'really', 'usa', 'like', 'just', 'run', 'game']\n",
      "\n",
      "\n",
      "Top 10 words for topic #2:\n",
      "['games', 'hitbox', 'streaming', 'running', 'run', 'like', 'time', 've', 'just', 'game']\n",
      "\n",
      "\n",
      "Top 10 words for topic #3:\n",
      "['really', 'like', 'runs', 'games', 'wr', 'com', 'just', 'time', 'game', 'run']\n",
      "\n",
      "\n",
      "Top 10 words for topic #4:\n",
      "['deleted', 'www', 'speedrun', 'new', 'http', 'time', 'game', 'com', 'wr', 'run']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print words -- manually look at topics\n",
    "first_topic = LDA.components_[0]\n",
    "top_topic_words = first_topic.argsort()[-10:]\n",
    "\n",
    "# for i in top_topic_words:\n",
    "#     print(count_vect.get_feature_names()[i])\n",
    "\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    print(f'Top 10 words for topic #{i}:')\n",
    "    print([count_vect.get_feature_names()[i] for i in topic.argsort()[-10:]])\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 5)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of all topics to each document\n",
    "topic_values = LDA.transform(doc_term_matrix)\n",
    "topic_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[WR]Hotline Miami Any% NG in 20:16 by Dingodro...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Couple questions about Chrono Trigger Any%1) W...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[WR] Luigi's Mansion 100% new WR by Veman300! ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Jak and Daxter any% route?Does anyone know of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>[WR] Castlevania:Harmony Of Dissonance Maxim A...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>What do you consider some of the most impressi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Rayman PSX (emulator) in 1:24:05just noticed t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Anybody speedrun games for iOS/Android? Let's ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>SSX On Tour - The Peak Freeride in 14:00This i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Dark Souls 2 latest exe?Can someone post the l...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>[WR] Ennopp112 does it again (1:27:31)But the ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Turok 2 - SPEED RUN (Hard Mode) in 1:55:26 by ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>[WR] Veman300 has set 3 World Records in Luigi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>[WR]Doom: Memento Mori Single Segment UV Speed...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Game of the Year 2014: 420 Blaze It?[This game...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[WR] Super Mario Advance 2: SuperMarioWorld an...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>I've never done any speed runs before and I'm ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Is there any active [TES IV: Oblivion runners?...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Weekly Brag Thread (December 02)This thread is...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>[SM64] Very easy PSS &amp;lt;21 stratHey!\\n\\nThis ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data  Topic\n",
       "0   [WR]Hotline Miami Any% NG in 20:16 by Dingodro...      3\n",
       "1   Couple questions about Chrono Trigger Any%1) W...      3\n",
       "2   [WR] Luigi's Mansion 100% new WR by Veman300! ...      4\n",
       "3   Jak and Daxter any% route?Does anyone know of ...      0\n",
       "4   [WR] Castlevania:Harmony Of Dissonance Maxim A...      0\n",
       "5   What do you consider some of the most impressi...      1\n",
       "6   Rayman PSX (emulator) in 1:24:05just noticed t...      0\n",
       "7   Anybody speedrun games for iOS/Android? Let's ...      3\n",
       "8   SSX On Tour - The Peak Freeride in 14:00This i...      1\n",
       "9   Dark Souls 2 latest exe?Can someone post the l...      4\n",
       "10  [WR] Ennopp112 does it again (1:27:31)But the ...      4\n",
       "11  Turok 2 - SPEED RUN (Hard Mode) in 1:55:26 by ...      1\n",
       "12  [WR] Veman300 has set 3 World Records in Luigi...      4\n",
       "13  [WR]Doom: Memento Mori Single Segment UV Speed...      3\n",
       "14  Game of the Year 2014: 420 Blaze It?[This game...      3\n",
       "15  [WR] Super Mario Advance 2: SuperMarioWorld an...      4\n",
       "16  I've never done any speed runs before and I'm ...      2\n",
       "17  Is there any active [TES IV: Oblivion runners?...      1\n",
       "18  Weekly Brag Thread (December 02)This thread is...      3\n",
       "19  [SM64] Very easy PSS &lt;21 stratHey!\\n\\nThis ...      2"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the topic index with max value\n",
    "\n",
    "# #####This is for title + selftext#####\n",
    "# submission_dataset_three['Topic'] = topic_values.argmax(axis=1)\n",
    "# submission_dataset_three.head(10)\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "# title_selftext['Topic'] = topic_values.argmax(axis=1)\n",
    "# title_selftext.head(20)\n",
    "\n",
    "#####This is for title + selftext#####\n",
    "title_selftext_comment['Topic'] = topic_values.argmax(axis=1)\n",
    "title_selftext_comment.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
